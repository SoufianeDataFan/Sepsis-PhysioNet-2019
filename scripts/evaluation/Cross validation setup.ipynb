{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.651676911463388\n",
      "6.055785343090466\n",
      "fold 0\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\ttraining's auc: 0.95714\tvalid_1's auc: 0.876135\n",
      "fold 1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.962014\tvalid_1's auc: 0.870588\n",
      "[200]\ttraining's auc: 0.975406\tvalid_1's auc: 0.874786\n",
      "[300]\ttraining's auc: 0.984217\tvalid_1's auc: 0.876858\n",
      "[400]\ttraining's auc: 0.989614\tvalid_1's auc: 0.878141\n",
      "[500]\ttraining's auc: 0.993299\tvalid_1's auc: 0.878855\n",
      "[600]\ttraining's auc: 0.995726\tvalid_1's auc: 0.878863\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's auc: 0.994603\tvalid_1's auc: 0.879023\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.958101\tvalid_1's auc: 0.874688\n",
      "[200]\ttraining's auc: 0.972511\tvalid_1's auc: 0.879059\n",
      "[300]\ttraining's auc: 0.981704\tvalid_1's auc: 0.882853\n",
      "[400]\ttraining's auc: 0.987491\tvalid_1's auc: 0.885904\n",
      "[500]\ttraining's auc: 0.992177\tvalid_1's auc: 0.887276\n",
      "[600]\ttraining's auc: 0.994989\tvalid_1's auc: 0.888101\n",
      "[700]\ttraining's auc: 0.99669\tvalid_1's auc: 0.88799\n",
      "Early stopping, best iteration is:\n",
      "[646]\ttraining's auc: 0.995858\tvalid_1's auc: 0.888248\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.959436\tvalid_1's auc: 0.877042\n",
      "[200]\ttraining's auc: 0.973487\tvalid_1's auc: 0.883375\n",
      "[300]\ttraining's auc: 0.983048\tvalid_1's auc: 0.887896\n",
      "[400]\ttraining's auc: 0.988844\tvalid_1's auc: 0.890277\n",
      "[500]\ttraining's auc: 0.992698\tvalid_1's auc: 0.891525\n",
      "[600]\ttraining's auc: 0.99541\tvalid_1's auc: 0.892176\n",
      "[700]\ttraining's auc: 0.99696\tvalid_1's auc: 0.89192\n",
      "Early stopping, best iteration is:\n",
      "[636]\ttraining's auc: 0.996056\tvalid_1's auc: 0.892311\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.960108\tvalid_1's auc: 0.87753\n",
      "[200]\ttraining's auc: 0.974133\tvalid_1's auc: 0.883996\n",
      "[300]\ttraining's auc: 0.983246\tvalid_1's auc: 0.888908\n",
      "[400]\ttraining's auc: 0.988349\tvalid_1's auc: 0.891744\n",
      "[500]\ttraining's auc: 0.992551\tvalid_1's auc: 0.893343\n",
      "[600]\ttraining's auc: 0.995143\tvalid_1's auc: 0.894185\n",
      "[700]\ttraining's auc: 0.996718\tvalid_1's auc: 0.894579\n",
      "[800]\ttraining's auc: 0.997835\tvalid_1's auc: 0.894731\n",
      "Early stopping, best iteration is:\n",
      "[756]\ttraining's auc: 0.997392\tvalid_1's auc: 0.894931\n",
      "Feature        object\n",
      "importance    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sys import platform\n",
    "if platform == \"linux\":\n",
    "    # linux/\n",
    "    MAIN_DIR='C:/Users/soufiane.chami/Desktop/PhysioNet/PhysioNet2019/'\n",
    "    \n",
    "elif platform == \"darwin\":\n",
    "        # OS X\n",
    "    MAIN_DIR='/Users/macbook/Desktop/Submission_PhysioNet/'\n",
    "    \n",
    "elif platform == \"win32\":\n",
    "        # Windows...\n",
    "    MAIN_DIR='C:/Users/soufiane.chami/Desktop/PhysioNet/PhysioNet2019/'\n",
    "    \n",
    "    \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sys import platform\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import time \n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4590)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"Feature\", \"importance\"]].groupby(\"Feature\").mean().sort_values(by=\"importance\", ascending=False)[:10].index\n",
    "    best_features = feature_importance_df_[[\"Feature\", \"importance\"]].groupby(\"Feature\").mean().sort_values(by=\"importance\", ascending=False)[:35]\n",
    "    best_features.reset_index(inplace=True)\n",
    "    print(best_features.dtypes)\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"Feature\", data=best_features)\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances.png')\n",
    "\n",
    "    \n",
    "def load_data(list_of_files, INP_DIR, return_featues=False):\n",
    "    data = []\n",
    "    for file_name in tqdm(list_of_files): \n",
    "        subject= pd.read_csv(INP_DIR+ file_name, sep='|')\n",
    "        subject['time_flow']= subject.index.values + 1\n",
    "        subject['Subject_ID'] = file_name.split('.')[0]\n",
    "        subject = subject.set_index(['Subject_ID', 'time_flow'])\n",
    "        subject[\"SepsisLabel\"]= subject.SepsisLabel.values.max()\n",
    "        y_cols =[\"SepsisLabel\"]\n",
    "        features = [f for f in subject.columns if f not in y_cols+ ['ICULOS']]\n",
    "        subject= subject.interpolate()\n",
    "        subject.fillna(method='ffill', inplace=True)\n",
    "        subject.fillna(method='bfill', inplace=True)\n",
    "        subject.fillna(0, inplace=True)\n",
    "        data.append(subject.reset_index())\n",
    "        \n",
    "    data = pd.concat(data, axis=0, ignore_index=True)\n",
    "#     data.set_index(['Subject_ID','time_flow'], inplace=True)\n",
    "    target = data[['Subject_ID','SepsisLabel']]\n",
    "#     del data['SepsisLabel']\n",
    "    if return_featues: \n",
    "        return data,target, features\n",
    "    else: \n",
    "        return data,target\n",
    "    \n",
    "TRAIN_Info= MAIN_DIR +'setA'\n",
    "TEST_Info = MAIN_DIR +'setB/'\n",
    "TRAIN_DIR= MAIN_DIR +'training_setA/'\n",
    "TEST_DIR = MAIN_DIR +'training_setB/'\n",
    "train_files = os.listdir(TRAIN_Info)\n",
    "test_files = os.listdir(TEST_DIR)\n",
    "\n",
    "# TRAIN \n",
    "# outputs will have the following shape\n",
    "# df_train: (790215, 39), target:(790215, 2)\n",
    "# 9.6517% of sepsis subjects\n",
    "training_setA= pd.read_csv(MAIN_DIR +'setA'+'/'+'info_training_'+'setA'+'.csv')\n",
    "yes_sepsis_setA= pd.read_csv(MAIN_DIR +'setA'+'/'+'yes_epsis_subject_id'+'setA'+'.csv')\n",
    "no_sepsis_setA= pd.read_csv(MAIN_DIR +'setA'+'/'+'no_Sepsis_subject_id'+'setA'+'.csv')\n",
    "print(str(yes_sepsis_setA.shape[0]/no_sepsis_setA.shape[0]*100))\n",
    "\n",
    "# TEST \n",
    "# outputs will have the following shape\n",
    "# df_train: (761995, 39), target: (761995, 2)\n",
    "# 6.0558% of sepsis subjects\n",
    "training_setB= pd.read_csv(MAIN_DIR +'setB'+'/'+'info_training_'+'setB'+'.csv')\n",
    "yes_sepsis_setB= pd.read_csv(MAIN_DIR +'setB'+'/'+'yes_epsis_subject_id'+'setB'+'.csv')\n",
    "no_sepsis_setB= pd.read_csv(MAIN_DIR +'setB'+'/'+'no_Sepsis_subject_id'+'setB'+'.csv')\n",
    "print(str(yes_sepsis_setB.shape[0]/no_sepsis_setB.shape[0]*100))\n",
    "\n",
    "start_from_scratch=False\n",
    "\n",
    "if start_from_scratch:\n",
    "    \n",
    "    df_train , trn_target, features = load_data(training_setA.subject_id.values+'.psv',TRAIN_DIR,return_featues=True)\n",
    "    \n",
    "    df_train.to_csv(\"df_train_untouched.csv\", index=False)\n",
    "    trn_target.to_csv(\"target_train_untouched.csv\", index=False)\n",
    "    \n",
    "    df_test , target_test = load_data(training_setB.subject_id.values+'.psv',TEST_DIR,return_featues=False)\n",
    "    \n",
    "    df_test.to_csv(\"df_test_untouched.csv\", index=False)\n",
    "    target_test.to_csv(\"target_test_untouched.csv\", index=False)\n",
    "\n",
    "else: \n",
    "    MAIN_DIR= '/Users/macbook/OneDrive - North Dakota University System/PhysioNet Scripts/2019/Notebooks/LGBM/'\n",
    "    df_train= pd.read_csv(\"df_train_untouched.csv\")\n",
    "    trn_target= pd.read_csv(\"target_train_untouched.csv\")\n",
    "    \n",
    "    df_test= pd.read_csv(\"df_test_untouched.csv\")\n",
    "    target_test= pd.read_csv(\"target_test_untouched.csv\")\n",
    "\n",
    "    features= [f for f in df_train.columns if f not in ['ICULOS', 'SepsisLabel', 'Subject_ID']]\n",
    "\n",
    "    \n",
    "    \n",
    "is_sepsis = training_setA.SepsisLabel.values\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "param = {'num_leaves': 120,\n",
    "        'metric': 'auc',\n",
    "         'objective': 'binary',\n",
    "         'is_unbalance': True,  \n",
    "         'seed': 820,\n",
    "         'max_depth': -1,\n",
    "         'n_estimators': 90,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         'eval_metric': 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 4590}\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(training_setA.subject_id.values,is_sepsis)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    \n",
    "    \n",
    "    # load data based on the fold's indexes \n",
    "    \n",
    "    ##### train\n",
    "    trn_idx = df_train['Subject_ID'].isin(training_setA.subject_id.values[trn_idx].tolist())\n",
    "    \n",
    "    trn_data= lgb.Dataset(df_train[features][trn_idx], label=trn_target['SepsisLabel'][trn_idx].values)\n",
    "    \n",
    "    \n",
    "    ##### validation\n",
    "    val_idx = df_train['Subject_ID'].isin(training_setA.subject_id.values[val_idx].tolist())\n",
    "    \n",
    "    val_data= lgb.Dataset(df_train[features][val_idx], label=trn_target['SepsisLabel'][val_idx].values)\n",
    "    \n",
    "  \n",
    "    # train lgb\n",
    "    num_round = 1000\n",
    "    clf = lgb.train(param, trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100, early_stopping_rounds = 100)\n",
    "        \n",
    "    oof[val_idx] = clf.predict(df_train[features][val_idx],\n",
    "                               num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "display_importances(feature_importance_df)    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save_model('lgb_classifier.txt', num_iteration=clf.best_iteration)\n",
    "model = lgb.Booster(model_file='lgb_classifier.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import numpy as np, pandas as pd\n",
    "import os, shutil, zipfile\n",
    "\n",
    "\n",
    "def build_data(engine, time, x, max_time, is_test):\n",
    "\n",
    "\n",
    "    return out_x, out_y\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def load_sepsis_model():\n",
    "    \n",
    "#     from keras.models import load_model\n",
    "    model = lgb.Booster(model_file='lgb_classifier.txt')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def load_challenge_data(file):\n",
    "    subject=  pd.read_csv(file, sep = \"|\")\n",
    "    subject= pd.read_csv(INP_DIR+ file_name, sep='|')\n",
    "    subject['time_flow']= subject.index.values + 1\n",
    "    subject['Subject_ID'] = file_name.split('.')[0]\n",
    "    subject = subject.set_index(['Subject_ID', 'time_flow'])\n",
    "    subject[\"SepsisLabel\"]= subject.SepsisLabel.values.max()\n",
    "    y_cols =[\"SepsisLabel\"]\n",
    "    features = [f for f in subject.columns if f not in y_cols+ ['ICULOS']]\n",
    "    subject= subject.interpolate()\n",
    "    subject.fillna(method='ffill', inplace=True)\n",
    "    subject.fillna(method='bfill', inplace=True)\n",
    "    subject.fillna(0, inplace=True)\n",
    "\n",
    "    return subject\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sepsis_score(test, model):\n",
    "\n",
    "#     print(\"data dhas been built .......\")\n",
    "    # Make some predictions and put them alongside the real TTE and event indicator values\n",
    "    test_predict = 1- model.predict(test)\n",
    "    labels = (test_predict>0.4).astype(int)\n",
    "    \n",
    "    return scores, labels\n",
    " \n",
    "\n",
    "\n",
    "import numpy as np, os, sys\n",
    "# from get_sepsis_score import load_sepsis_model, get_sepsis_score\n",
    "\n",
    "def save_challenge_predictions(file, scores, labels):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write('PredictedProbability|PredictedLabel\\n')\n",
    "        for (s, l) in zip(scores, labels):\n",
    "            f.write('%g|%d\\n' % (s, l))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Parse arguments.\n",
    "    if len(sys.argv) != 3:\n",
    "        raise Exception('Include the input and output directories as arguments, e.g., python driver.py input output.')\n",
    "\n",
    "    input_directory = '/Users/macbook/Desktop/Submission_PhysioNet/training_setB/'  #sys.argv[1]\n",
    "    output_directory = '/Users/macbook/Desktop/Submission_PhysioNet/predictions_setB/' #sys.argv[2]\n",
    "\n",
    "    # Find files.\n",
    "    files = []\n",
    "    for f in os.listdir(input_directory):\n",
    "        if os.path.isfile(os.path.join(input_directory, f)) and not f.lower().startswith('.') and f.lower().endswith('psv'):\n",
    "            files.append(f)\n",
    "\n",
    "    if not os.path.isdir(output_directory):\n",
    "        os.mkdir(output_directory)\n",
    "\n",
    "    # Load model.\n",
    "    model = load_sepsis_model()\n",
    "    files = sorted(files)\n",
    "    # Iterate over files.\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    for f in tqdm(files):\n",
    "        # Load data.\n",
    "        input_file = os.path.join(input_directory, f)\n",
    "        data = load_challenge_data(input_file)\n",
    "\n",
    "        # Make predictions.\n",
    "        num_rows = len(data)\n",
    "        scores = np.zeros(num_rows)\n",
    "        labels = np.zeros(num_rows)\n",
    "        current_data = data\n",
    "        current_score, current_label = get_sepsis_score(current_data, model)\n",
    "\n",
    "        scores= current_score\n",
    "        labels= current_label\n",
    "        # Save results.\n",
    "        output_file = os.path.join(output_directory, f)\n",
    "        save_challenge_predictions(output_file, scores, labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_challenge_data(file):\n",
    "    subject=  pd.read_csv(file, sep = \"|\")\n",
    "    subject['time_flow']= subject.index.values + 1\n",
    "    subject['Subject_ID'] = file.split('/')[-1].split('.')[0]\n",
    "    subject = subject.set_index(['Subject_ID', 'time_flow'])\n",
    "    subject[\"SepsisLabel\"]= subject.SepsisLabel.values.max()\n",
    "    y_cols =[\"SepsisLabel\"]\n",
    "    features = [f for f in subject.columns if f not in y_cols+ ['ICULOS']]\n",
    "    subject= subject.interpolate()\n",
    "    subject.fillna(method='ffill', inplace=True)\n",
    "    subject.fillna(method='bfill', inplace=True)\n",
    "    subject.fillna(0, inplace=True)\n",
    "\n",
    "    return subject\n",
    "\n",
    "\n",
    "test_df= load_challenge_data('/Users/macbook/Desktop/Submission_PhysioNet/training_setB/p100001.psv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15025147, 0.15025147, 0.15139939, 0.15139939, 0.14854631,\n",
       "       0.15139939, 0.15139939, 0.14854631, 0.14854631, 0.14854631,\n",
       "       0.15139939, 0.14854631, 0.14854631, 0.14854631, 0.15139939,\n",
       "       0.14854631, 0.14854631, 0.15139939, 0.15139939, 0.14854631,\n",
       "       0.14854631, 0.15139939, 0.15139939, 0.15025147])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
